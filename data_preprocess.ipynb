{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MDFeat,load,save\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import MDFeat\n",
    "from typing import List\n",
    "from transformers import pipeline,AutoModelForTokenClassification,AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data:List[MDFeat] = load(\"/home/tywang/MD/data/VUA/vua_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDFeat(sentence=\"Ca n't fail to be entertaining .\", verb_idx=2, verb='fail', label=0, addinfo1=[\"Ca n't fails to be entertaining .\", \"Ca n't failure to be entertaining .\", \"Ca n't failed to be entertaining .\", \"Ca n't succeed to be entertaining .\", \"Ca n't failing to be entertaining .\", \"Ca n't try to be entertaining .\", \"Ca n't attempt to be entertaining .\", \"Ca n't have to be entertaining .\", \"Ca n't cease to be entertaining .\"], addinfo2=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_sentence(unmasker,data:MDFeat):\n",
    "    unmasked_texts = []\n",
    "    sentence_template = data.sentence.split()\n",
    "    ori_token = sentence_template[data.verb_idx]\n",
    "    sentence_template[data.verb_idx] = '{}'\n",
    "    sentence_template = \" \".join(sentence_template)\n",
    "    input_sentence = sentence_template + \" \" + data.sentence\n",
    "    input_sentence = input_sentence.format(\"[MASK]\")\n",
    "    unmask_result = unmasker(input_sentence)\n",
    "    for result in unmask_result:\n",
    "        if result['token_str'].find():\n",
    "            unmasked_texts.append(sentence_template.format(\"<VERB> \"+result['token_str']+\" </VERB>\"))\n",
    "    return unmasked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/transformers/bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='/data/transformers/bert-base-uncased',device = 1,top_k =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15516/15516 [03:55<00:00, 65.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "    data[i].addinfo1 = get_mask_sentence(unmasker,data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to(保存到)  /home/tywang/MD/data/VUA/vua_train.pkl\n"
     ]
    }
   ],
   "source": [
    "save(data,\"/home/tywang/MD/data/VUA/vua_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDFeat(sentence=\"Ca n't fail to be entertaining .\", verb_idx=2, verb='fail', label=0, addinfo1=[\"Ca n't <VERB> fails </VERB> to be entertaining .\", \"Ca n't <VERB> failure </VERB> to be entertaining .\", \"Ca n't <VERB> failed </VERB> to be entertaining .\", \"Ca n't <VERB> succeed </VERB> to be entertaining .\", \"Ca n't <VERB> failing </VERB> to be entertaining .\", \"Ca n't <VERB> try </VERB> to be entertaining .\", \"Ca n't <VERB> attempt </VERB> to be entertaining .\", \"Ca n't <VERB> have </VERB> to be entertaining .\", \"Ca n't <VERB> cease </VERB> to be entertaining .\"], addinfo2=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_sentence(unmasker,text_arr:list):\n",
    "    \"\"\"\n",
    "        输入一个句子arr, 得到它的预测token以及预测的score\n",
    "    \"\"\"\n",
    "    unmask_result = unmasker(text_arr)\n",
    "    return_results = []\n",
    "    for result in unmask_result:\n",
    "        return_result = []\n",
    "        for idx,token in enumerate(result):\n",
    "            return_result.append((token['score'],token['token_str']))\n",
    "        return_results.append(return_result)\n",
    "    return return_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.10721077024936676, 'fashion'),\n",
       "  (0.08796188235282898, 'role'),\n",
       "  (0.05333735793828964, 'new'),\n",
       "  (0.046707648783922195, 'super'),\n",
       "  (0.027107620611786842, 'fine'),\n",
       "  (0.02393934689462185, 'good'),\n",
       "  (0.021875906735658646, 'model'),\n",
       "  (0.0213792622089386, 'great'),\n",
       "  (0.01942354626953602, 'business'),\n",
       "  (0.016654005274176598, 'fitness')],\n",
       " [(0.10721077024936676, 'fashion'),\n",
       "  (0.08796188235282898, 'role'),\n",
       "  (0.05333735793828964, 'new'),\n",
       "  (0.046707648783922195, 'super'),\n",
       "  (0.027107620611786842, 'fine'),\n",
       "  (0.02393934689462185, 'good'),\n",
       "  (0.021875906735658646, 'model'),\n",
       "  (0.0213792622089386, 'great'),\n",
       "  (0.01942354626953602, 'business'),\n",
       "  (0.016654005274176598, 'fitness')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mask_sentence(unmasker,[\"Hello I'm a [MASK] model.\",\"Hello I'm a [MASK] model.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"test\"\n",
    "df = pd.read_csv(\"/home/tywang/MD/data/VUA/VUA_formatted_{}.csv\".format(mode), encoding = \"ISO-8859-1\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_idx</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>verb</th>\n",
       "      <th>sentence</th>\n",
       "      <th>verb_idx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3m-fragment02</td>\n",
       "      <td>45</td>\n",
       "      <td>cross</td>\n",
       "      <td>Design : Crossed lines over the toytown tram :...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a3m-fragment02</td>\n",
       "      <td>45</td>\n",
       "      <td>say</td>\n",
       "      <td>Design : Crossed lines over the toytown tram :...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3m-fragment02</td>\n",
       "      <td>47</td>\n",
       "      <td>know</td>\n",
       "      <td>MODERN trams , as most continental Europeans k...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a3m-fragment02</td>\n",
       "      <td>47</td>\n",
       "      <td>shakdevoure</td>\n",
       "      <td>MODERN trams , as most continental Europeans k...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a3m-fragment02</td>\n",
       "      <td>47</td>\n",
       "      <td>rattle</td>\n",
       "      <td>MODERN trams , as most continental Europeans k...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text_idx  sentence_idx         verb  \\\n",
       "0  a3m-fragment02            45        cross   \n",
       "1  a3m-fragment02            45          say   \n",
       "2  a3m-fragment02            47         know   \n",
       "3  a3m-fragment02            47  shakdevoure   \n",
       "4  a3m-fragment02            47       rattle   \n",
       "\n",
       "                                            sentence  verb_idx  label  \n",
       "0  Design : Crossed lines over the toytown tram :...         2      1  \n",
       "1  Design : Crossed lines over the toytown tram :...        20      0  \n",
       "2  MODERN trams , as most continental Europeans k...         7      0  \n",
       "3  MODERN trams , as most continental Europeans k...        10      0  \n",
       "4  MODERN trams , as most continental Europeans k...        12      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df['sentence'].values\n",
    "verb_idx = df['verb_idx'].values\n",
    "verb = df['verb'].values\n",
    "label = df['label'].values\n",
    "senetnce = [item.strip() for item in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mohx = list()\n",
    "for text, verb_id, v, gt in zip(senetnce,verb_idx,verb,label):\n",
    "    feat = MDFeat(\n",
    "        sentence=text,\n",
    "        verb_idx = verb_id,\n",
    "        verb = v,\n",
    "        label = gt,\n",
    "        addinfo1=None,\n",
    "        addinfo2=None\n",
    "    )\n",
    "    mohx.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MDFeat(sentence='The trouble with all the views which we have looked at is that they tie the notion of autonomy firmly and solely to that of knowledge interpreted in either a broad or narrow sense .', verb_idx=9, verb='look', label=1, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='The trouble with all the views which we have looked at is that they tie the notion of autonomy firmly and solely to that of knowledge interpreted in either a broad or narrow sense .', verb_idx=14, verb='tie', label=1, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='The trouble with all the views which we have looked at is that they tie the notion of autonomy firmly and solely to that of knowledge interpreted in either a broad or narrow sense .', verb_idx=26, verb='interpret', label=1, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='That it is firmly tied must be correct ; the inhabitants of Brave New World are not autonomous precisely because they are denied access to relevant information .', verb_idx=4, verb='tie', label=1, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='That it is firmly tied must be correct ; the inhabitants of Brave New World are not autonomous precisely because they are denied access to relevant information .', verb_idx=22, verb='deny', label=0, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='Aristotle said something very interesting in that extract from the Politics which I quoted earlier ; he said that women have a deliberative faculty but that it lacks full authority .', verb_idx=1, verb='say', label=1, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='Aristotle said something very interesting in that extract from the Politics which I quoted earlier ; he said that women have a deliberative faculty but that it lacks full authority .', verb_idx=13, verb='quote', label=0, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='Aristotle said something very interesting in that extract from the Politics which I quoted earlier ; he said that women have a deliberative faculty but that it lacks full authority .', verb_idx=1, verb='say', label=1, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='Aristotle said something very interesting in that extract from the Politics which I quoted earlier ; he said that women have a deliberative faculty but that it lacks full authority .', verb_idx=27, verb='lack', label=0, addinfo1=None, addinfo2=None),\n",
       " MDFeat(sentence='What did he mean ?', verb_idx=3, verb='mean', label=0, addinfo1=None, addinfo2=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mohx[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to(保存到)  /home/tywang/MD/data/VUA/vua_test.pkl\n"
     ]
    }
   ],
   "source": [
    "save(mohx,\"/home/tywang/MD/data/VUA/vua_{}.pkl\".format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8253c7f502ea70b487a77220de32f8fb140e5d19dcd4a68136989b39eca91c04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
