{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load,save\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import MDFeat\n",
    "from typing import List\n",
    "from transformers import pipeline,AutoModelForTokenClassification,AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all', base_temperature=0.07, device=torch.device('cpu')):\n",
    "        \"\"\"\n",
    "        :param temperature:  t\n",
    "        :param contrast_mode:\n",
    "        :param base_temperature:\n",
    "        \"\"\"\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.device = device\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        \"\"\"\n",
    "        both `labels` and `mask` are None, it degenerates to SimCLR unsupervised loss\n",
    "        :param features:  B^alpha 中的2个augment sentence拼接而成,[Batch_size,2*S_L,d_model] 三维\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = features.shape[0]\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)  # (Batch_size+2*S_L,)\n",
    "\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(self.device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(self.device)\n",
    "        else:\n",
    "            print(mask)\n",
    "            mask = mask.float().to(self.device)\n",
    "\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(self.device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        # loss = - mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLoss = SupConLoss(temperature=1,contrast_mode='one',base_temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(torch.rand([3,10])).reshape(1,-1)\n",
    "y = torch.FloatTensor(torch.rand([3,10])).reshape(1,-1)\n",
    "# [Batch_size,2*S_L,d_model]\n",
    "feat1 = F.normalize(x, dim=1)  # head embed_size->128 线性层\n",
    "feat2 = F.normalize(y, dim=1)\n",
    "features = torch.cat([feat1.unsqueeze(1), feat2.unsqueeze(1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.4901e-08)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLoss(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(torch.rand([4,10]))\n",
    "y = torch.FloatTensor(torch.rand([4,10]))\n",
    " \n",
    "similarity = torch.cosine_similarity(x, x, dim=1)\n",
    " \n",
    "loss = 1 - similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\"/home/tywang/MD/data/VUA/vua_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[88].addinfo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-fold 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pickle \n",
    "def load(path_name: object) -> object:\n",
    "    with open(path_name, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "@dataclass\n",
    "class MDFeat:\n",
    "    sentence: str\n",
    "    verb_idx: int\n",
    "    verb:str\n",
    "    label: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vua_pos = load(\"/home/tywang/MD/data/VUA_ALL_POS/vua_pos_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MDFeat' object has no attribute 'addinfo1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/dataclasses.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MD/utils.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MDFeat' object has no attribute 'addinfo1'"
     ]
    }
   ],
   "source": [
    "vua_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data:List[MDFeat] = load(\"/home/tywang/MD/data/VUA/vua_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDFeat(sentence=\"Ca n't fail to be entertaining .\", verb_idx=2, verb='fail', label=0, addinfo1=[\"Ca n't fails to be entertaining .\", \"Ca n't failure to be entertaining .\", \"Ca n't failed to be entertaining .\", \"Ca n't succeed to be entertaining .\", \"Ca n't failing to be entertaining .\", \"Ca n't try to be entertaining .\", \"Ca n't attempt to be entertaining .\", \"Ca n't have to be entertaining .\", \"Ca n't cease to be entertaining .\"], addinfo2=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_sentence(unmasker,data:MDFeat):\n",
    "    unmasked_texts = []\n",
    "    sentence_template = data.sentence.split()\n",
    "    ori_token = sentence_template[data.verb_idx]\n",
    "    sentence_template[data.verb_idx] = '{}'\n",
    "    sentence_template = \" \".join(sentence_template)\n",
    "    input_sentence = sentence_template + \" \" + data.sentence\n",
    "    input_sentence = input_sentence.format(\"[MASK]\")\n",
    "    unmask_result = unmasker(input_sentence)\n",
    "    for result in unmask_result:\n",
    "        if result['token_str'].find():\n",
    "            unmasked_texts.append(sentence_template.format(\"<VERB> \"+result['token_str']+\" </VERB>\"))\n",
    "    return unmasked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDFeat(sentence=\"Ca n't fail to be entertaining .\", verb_idx=2, verb='fail', label=0, addinfo1=[\"Ca n't <VERB> fails </VERB> to be entertaining .\", \"Ca n't <VERB> failure </VERB> to be entertaining .\", \"Ca n't <VERB> failed </VERB> to be entertaining .\", \"Ca n't <VERB> succeed </VERB> to be entertaining .\", \"Ca n't <VERB> failing </VERB> to be entertaining .\", \"Ca n't <VERB> try </VERB> to be entertaining .\", \"Ca n't <VERB> attempt </VERB> to be entertaining .\", \"Ca n't <VERB> have </VERB> to be entertaining .\", \"Ca n't <VERB> cease </VERB> to be entertaining .\"], addinfo2=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_mask(unmasker,data:MDFeat):\n",
    "    normal_texts = []\n",
    "    splitted_sentence = data.sentence.split()\n",
    "    # 随机选择一个位置\n",
    "    pausible_index = [i for i in range(len(splitted_sentence)) if i!=data.verb_idx]\n",
    "    random.shuffle(pausible_index)\n",
    "    for normal_index in pausible_index[:3]:\n",
    "        # 随机替换该位置为mask\n",
    "        count = 0\n",
    "        splitted_sentence = data.sentence.split()\n",
    "        ori_word = splitted_sentence[normal_index]\n",
    "        splitted_sentence[normal_index] = ' {} '\n",
    "        sentence_template = ' '.join(splitted_sentence)\n",
    "        # print(sentence_template)\n",
    "        masked_sentence = sentence_template.format(\"[MASK]\")\n",
    "        # 生成mask token\n",
    "        unmask_result = unmasker(masked_sentence)\n",
    "        for result in unmask_result:\n",
    "            if count==2:break\n",
    "            if result['token_str']!=ori_word.strip().lower():\n",
    "                # print(result['token_str'])\n",
    "                normal_texts.append(sentence_template.format(result['token_str']))\n",
    "                count+=1\n",
    "    final_sentence = []\n",
    "    for t in normal_texts:\n",
    "        sentence_split = t.split()\n",
    "        sentence_split[data.verb_idx] = \" <VERB> {} </VERB> \".format(sentence_split[data.verb_idx])\n",
    "        t = \" \".join(sentence_split)\n",
    "        final_sentence.append(t)\n",
    "    return final_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/transformers/bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='/data/transformers/bert-base-uncased',device = 1,top_k =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15516/15516 [11:38<00:00, 22.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_i in tqdm(data):\n",
    "    data_i.addinfo2 = get_normal_mask(unmasker,data_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =[]\n",
    "for id,data_i in enumerate(data):\n",
    "    if len(data_i.addinfo2)==0:\n",
    "        index.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tywang/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for id in index:\n",
    "    data[id].addinfo2 = get_normal_mask(unmasker,data[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in index:\n",
    "    data[id].addinfo2 = \" <VERB> {} </VERB> \".format(data[id].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to(保存到)  /home/tywang/MD/data/VUA/vua_train_mlm.pkl\n"
     ]
    }
   ],
   "source": [
    "save(data,\"/home/tywang/MD/data/VUA/vua_train_mlm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15516/15516 [03:55<00:00, 65.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "    data[i].addinfo1 = get_mask_sentence(unmasker,data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to(保存到)  /home/tywang/MD/data/VUA/vua_train.pkl\n"
     ]
    }
   ],
   "source": [
    "save(data,\"/home/tywang/MD/data/VUA/vua_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDFeat(sentence=\"Ca n't fail to be entertaining .\", verb_idx=2, verb='fail', label=0, addinfo1=[\"Ca n't <VERB> fails </VERB> to be entertaining .\", \"Ca n't <VERB> failure </VERB> to be entertaining .\", \"Ca n't <VERB> failed </VERB> to be entertaining .\", \"Ca n't <VERB> succeed </VERB> to be entertaining .\", \"Ca n't <VERB> failing </VERB> to be entertaining .\", \"Ca n't <VERB> try </VERB> to be entertaining .\", \"Ca n't <VERB> attempt </VERB> to be entertaining .\", \"Ca n't <VERB> have </VERB> to be entertaining .\", \"Ca n't <VERB> cease </VERB> to be entertaining .\"], addinfo2=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_sentence(unmasker,text_arr:list):\n",
    "    \"\"\"\n",
    "        输入一个句子arr, 得到它的预测token以及预测的score\n",
    "    \"\"\"\n",
    "    unmask_result = unmasker(text_arr)\n",
    "    return_results = []\n",
    "    for result in unmask_result:\n",
    "        return_result = []\n",
    "        for idx,token in enumerate(result):\n",
    "            return_result.append((token['score'],token['token_str']))\n",
    "        return_results.append(return_result)\n",
    "    return return_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.10721077024936676, 'fashion'),\n",
       "  (0.08796188235282898, 'role'),\n",
       "  (0.05333735793828964, 'new'),\n",
       "  (0.046707648783922195, 'super'),\n",
       "  (0.027107620611786842, 'fine'),\n",
       "  (0.02393934689462185, 'good'),\n",
       "  (0.021875906735658646, 'model'),\n",
       "  (0.0213792622089386, 'great'),\n",
       "  (0.01942354626953602, 'business'),\n",
       "  (0.016654005274176598, 'fitness')],\n",
       " [(0.10721077024936676, 'fashion'),\n",
       "  (0.08796188235282898, 'role'),\n",
       "  (0.05333735793828964, 'new'),\n",
       "  (0.046707648783922195, 'super'),\n",
       "  (0.027107620611786842, 'fine'),\n",
       "  (0.02393934689462185, 'good'),\n",
       "  (0.021875906735658646, 'model'),\n",
       "  (0.0213792622089386, 'great'),\n",
       "  (0.01942354626953602, 'business'),\n",
       "  (0.016654005274176598, 'fitness')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mask_sentence(unmasker,[\"Hello I'm a [MASK] model.\",\"Hello I'm a [MASK] model.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg2</th>\n",
       "      <th>verb</th>\n",
       "      <th>sentence</th>\n",
       "      <th>verb_idx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absorb</td>\n",
       "      <td>He absorbed the knowledge or beliefs of his t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absorb</td>\n",
       "      <td>He absorbed the costs for the accident .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absorb</td>\n",
       "      <td>The sales tax is absorbed into the state inco...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>immigrant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absorb</td>\n",
       "      <td>The immigrants were quickly absorbed into soc...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absorb</td>\n",
       "      <td>Her interest in butterflies absorbs her compl...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        arg1  arg2    verb                                           sentence  \\\n",
       "0  knowledge   NaN  absorb   He absorbed the knowledge or beliefs of his t...   \n",
       "1       cost   NaN  absorb           He absorbed the costs for the accident .   \n",
       "2        tax   NaN  absorb   The sales tax is absorbed into the state inco...   \n",
       "3  immigrant   NaN  absorb   The immigrants were quickly absorbed into soc...   \n",
       "4   interest   NaN  absorb   Her interest in butterflies absorbs her compl...   \n",
       "\n",
       "   verb_idx  label  \n",
       "0         1      1  \n",
       "1         1      1  \n",
       "2         4      1  \n",
       "3         4      1  \n",
       "4         4      1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/tywang/MD/data/MOH-X/MOH-X_formatted_svo_cleaned.csv\", encoding = \"ISO-8859-1\",low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df['sentence'].values\n",
    "verb_idx = df['verb_idx'].values\n",
    "verb = df['verb'].values\n",
    "label = df['label'].values\n",
    "senetnce = [item.strip() for item in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mohx = list()\n",
    "for text, verb_id, v, gt in zip(senetnce,verb_idx,verb,label):\n",
    "    feat = MDFeat(\n",
    "        sentence=text,\n",
    "        verb_idx = verb_id,\n",
    "        verb = v,\n",
    "        label = gt,\n",
    "        addinfo1=None,\n",
    "        addinfo2=None\n",
    "    )\n",
    "    mohx.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(mohx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 64]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx0_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx0_train.pkl\n",
      "[64, 128]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx1_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx1_train.pkl\n",
      "[128, 192]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx2_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx2_train.pkl\n",
      "[192, 256]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx3_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx3_train.pkl\n",
      "[256, 320]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx4_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx4_train.pkl\n",
      "[320, 384]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx5_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx5_train.pkl\n",
      "[384, 448]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx6_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx6_train.pkl\n",
      "[448, 512]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx7_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx7_train.pkl\n",
      "[512, 576]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx8_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx8_train.pkl\n",
      "[576, 640]\n",
      "64\n",
      "583\n",
      "647\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx9_val.pkl\n",
      "save to(保存到)  /home/tywang/MD/data/MOH-X/mohx9_train.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_ten = int(0.1*len(mohx))\n",
    "for i in range(10):\n",
    "    select_range = [i*n_ten,(1+i)*n_ten]\n",
    "    mohx_1 = mohx[select_range[0]:select_range[1]]\n",
    "    mohx_9 = mohx[:select_range[0]]+mohx[select_range[1]:]\n",
    "    print(select_range)\n",
    "    print(len(mohx_1))\n",
    "    print(len(mohx_9))\n",
    "    print(len(mohx_1)+len(mohx_9))\n",
    "    save(mohx_1,\"/home/tywang/MD/data/MOH-X/mohx{}_val.pkl\".format(i))\n",
    "    save(mohx_9,\"/home/tywang/MD/data/MOH-X/mohx{}_train.pkl\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"dev\"\n",
    "df = pd.read_csv(\"/home/tywang/MD/data/VUA_ALL_POS/VUA_ALL_POS_{}.csv\".format(mode), encoding = \"ISO-8859-1\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_idx</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acj-fragment01</td>\n",
       "      <td>148</td>\n",
       "      <td>Four</td>\n",
       "      <td>Four alternative approaches have been describe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NUM</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acj-fragment01</td>\n",
       "      <td>148</td>\n",
       "      <td>alternative</td>\n",
       "      <td>Four alternative approaches have been describe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acj-fragment01</td>\n",
       "      <td>148</td>\n",
       "      <td>approaches</td>\n",
       "      <td>Four alternative approaches have been describe...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acj-fragment01</td>\n",
       "      <td>148</td>\n",
       "      <td>have</td>\n",
       "      <td>Four alternative approaches have been describe...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acj-fragment01</td>\n",
       "      <td>148</td>\n",
       "      <td>been</td>\n",
       "      <td>Four alternative approaches have been describe...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text_idx  sentence_idx         word  \\\n",
       "0  acj-fragment01           148         Four   \n",
       "1  acj-fragment01           148  alternative   \n",
       "2  acj-fragment01           148   approaches   \n",
       "3  acj-fragment01           148         have   \n",
       "4  acj-fragment01           148         been   \n",
       "\n",
       "                                            sentence  word_idx  label   pos  \\\n",
       "0  Four alternative approaches have been describe...         0      0   NUM   \n",
       "1  Four alternative approaches have been describe...         1      0   ADJ   \n",
       "2  Four alternative approaches have been describe...         2      1  NOUN   \n",
       "3  Four alternative approaches have been describe...         3      0  VERB   \n",
       "4  Four alternative approaches have been describe...         4      0  VERB   \n",
       "\n",
       "      genre  \n",
       "0  academic  \n",
       "1  academic  \n",
       "2  academic  \n",
       "3  academic  \n",
       "4  academic  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df['sentence'].values\n",
    "verb_idx = df['word_idx'].values\n",
    "verb = df['word'].values\n",
    "label = df['label'].values\n",
    "senetnce = [item.strip() for item in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mohx = list()\n",
    "for text, verb_id, v, gt in zip(senetnce,verb_idx,verb,label):\n",
    "    feat = MDFeat(\n",
    "        sentence=text,\n",
    "        verb_idx = verb_id,\n",
    "        verb = v,\n",
    "        label = gt,\n",
    "        addinfo1=None,\n",
    "        addinfo2=None\n",
    "    )\n",
    "    mohx.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([MDFeat(sentence='The section describing the operation of the system should cover not only how the system operates but also how the user can operate it .', verb_idx=20, verb='user', label=0, addinfo1=None, addinfo2=None),\n",
       "  MDFeat(sentence='The section describing the operation of the system should cover not only how the system operates but also how the user can operate it .', verb_idx=21, verb='can', label=0, addinfo1=None, addinfo2=None),\n",
       "  MDFeat(sentence='The section describing the operation of the system should cover not only how the system operates but also how the user can operate it .', verb_idx=22, verb='operate', label=0, addinfo1=None, addinfo2=None),\n",
       "  MDFeat(sentence='The section describing the operation of the system should cover not only how the system operates but also how the user can operate it .', verb_idx=23, verb='it', label=0, addinfo1=None, addinfo2=None),\n",
       "  MDFeat(sentence='The section describing the operation of the system should cover not only how the system operates but also how the user can operate it .', verb_idx=24, verb='.', label=0, addinfo1=None, addinfo2=None)],\n",
       " 38628)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mohx[-5:],len(mohx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38628"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mohx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to(保存到)  /home/tywang/MD/data/VUA_ALL_POS/vua_pos_dev.pkl\n"
     ]
    }
   ],
   "source": [
    "save(mohx,\"/home/tywang/MD/data/VUA_ALL_POS/vua_pos_{}.pkl\".format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8253c7f502ea70b487a77220de32f8fb140e5d19dcd4a68136989b39eca91c04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
